# Ollama 서버용 Dockerfile (Render 프리플랜 최적화)
FROM ollama/ollama:latest

# Ollama 서버 포트 설정
EXPOSE 11434

# 환경 변수 설정
ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_ORIGINS=*
ENV OLLAMA_KEEP_ALIVE=24h
ENV OLLAMA_NUM_PARALLEL=1
ENV OLLAMA_MAX_LOADED_MODELS=1

# 헬스체크 추가
HEALTHCHECK --interval=60s --timeout=30s --start-period=120s --retries=2 \
  CMD curl -f http://localhost:11434/api/tags || exit 1

# 시작 스크립트 생성
RUN echo '#!/bin/bash\n\
# Ollama 서버 시작\n\
ollama serve &\n\
\n\
# 서버 시작 대기\n\
sleep 10\n\
\n\
# 모델 다운로드\n\
echo "Downloading qwen2.5:1.5b..."\n\
ollama pull qwen2.5:1.5b\n\
\n\
echo "Downloading nomic-embed-text..."\n\
ollama pull nomic-embed-text\n\
\n\
echo "All models downloaded successfully!"\n\
\n\
# 서버 유지\n\
wait' > /start.sh && chmod +x /start.sh

# 시작 스크립트 실행
CMD ["/bin/bash", "/start.sh"]